{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "from math import *\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 29: Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last lesson, we studied method of moments estimators. These estimators are obtained by setting the moments of a distribution equal to the sample moments obtained from an independent random sample, and then solving for the parameters of interest. As we saw, method of moments estimators are relatively easy to find, but don't always make sense (as in the case of $X\\sim \\textsf{Unif}(0,b)$.) \n",
    "\n",
    "Another way to estimate is by maximizing the likelihood function. First, we should introduce the likelihood function. The likelihood function, $L(\\theta \\mid \\textbf{x})$, is a function of $\\theta$ that is larger for likelier values of $\\theta$. Finding the value of $\\theta$ that maximizes this function yields a maximum likelihood estimator, or $\\hat{\\theta}_{ML}$. \n",
    "\n",
    "Let $X_1,X_2,...,X_n$ be a sequence of iid random variables with mass or density function $f(x;\\theta)$. The likelihood function is given by:\n",
    "\n",
    "$$\n",
    "L(\\theta\\mid \\textbf{x}) = \\prod_{i=1}^n f(x_i;\\theta)\n",
    "$$\n",
    "\n",
    "Often, it is easier to deal with the log of the likelihood function. This is because the log of a product is the sum of individual logs, which is often analytically \"nicer\". The log-likelihood function is denoted as $l(\\theta \\mid \\textbf{x})$ and is given by:\n",
    "\n",
    "$$\n",
    "l(\\theta\\mid\\textbf{x})=\\log \\prod_{i=1}^n f(x_i;\\theta) = \\sum_{i=1}^n \\log f(x_i;\\theta)\n",
    "$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Class note: **x** refers to the* vector *x.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Exponential Distribution\n",
    "\n",
    "Suppose $X_1,X_2,...,X_n$ is an iid sequence of random variables from the exponential distribution with unknown parameter $\\lambda$. I would like to obtain $\\hat{\\lambda}_{ML}$, the maximum likelihood estimate of $\\lambda$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that if $X\\sim \\textsf{Exp}(\\lambda)$, then $f(x)=\\lambda e^{-\\lambda x}$. So,\n",
    "\n",
    "$$\n",
    "L(\\theta\\mid \\textbf{x}) = \\prod_{i=1}^n f(x_i;\\theta) = \\prod_{i=1}^n \\lambda e^{-\\lambda x_i} = \\lambda^n e^{-\\lambda \\sum x_i}\n",
    "$$\n",
    "\n",
    "Maximizing this through differentiation looks difficult. Let's consider the log-likelihood instead: \n",
    "\n",
    "$$\n",
    "l(\\theta\\mid \\textbf{x}) = n \\log \\lambda - \\lambda \\sum x_i\n",
    "$$\n",
    "\n",
    "This looks easier. Take the derivative with respect to $\\lambda$ and set to 0. Then solve for $\\lambda$. I leave this next step to you. How does your answer compare to $\\hat{\\lambda}_{MoM}$? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "l(\\theta\\mid \\textbf{x}) &= n \\log \\lambda - \\lambda \\sum x_i\\\\\n",
    "\\frac{d}{d\\lambda}(l(\\theta\\mid\\textbf{x})) &= \\frac{d}{d\\lambda}(n\\log\\lambda) - \\frac{d}{d\\lambda}\\left(\\lambda\\sum x_i\\right)\\\\\n",
    "\\text{Rel Max for likelihood (L) of }&\\lambda\\text{ is at same place as max of l, so}\\\\\n",
    "0&=n\\left(\\frac{1}{\\lambda}\\right) - \\sum x_i\\\\\n",
    "\\sum x_i &= \\frac{n}{\\lambda}\\\\\n",
    "\\lambda&=\\frac{n}{ \\sum x_i }\\\\\n",
    "\\hat{\\lambda}_{MoM}&=\\frac{1}{ \\bar{X} }\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{d^2}{d\\lambda^2}=\\frac{-n}{\\lambda^2}$, so l has no minimums, only a maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Uniform Distribution\n",
    "\n",
    "Suppose $X_1,X_2,...,X_n$ is an iid sequence of random variables from the continuous uniform distribution on $0 \\leq X \\leq b$ with unknown parameter $b$. I would like to obtain $\\hat{b}_{ML}$, the maximum likelihood estimate of $b$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is trickier since the domain of $X$ depends on the parameter we are trying to estimate. So I will start you off with a hint. The pdf of $X$ is $f(x)=\\frac{1}{b}$ where $0\\leq x \\leq b$ and 0 otherwise. Another way to write this is with indicator functions:\n",
    "\n",
    "$$\n",
    "f(x)={1\\over b}I(x\\leq b)\n",
    "$$\n",
    "\n",
    "where $I(x\\leq b)$ is equal to 1 if $x \\leq b$ and 0 otherwise. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "L(b\\mid \\textbf{x})&=\\prod_{i=1}^n f(x_i;b)\\\\\n",
    "&=\\prod_{i=1}^n \\left(\\frac{1}{b} I(x_i\\leq b) \\right)\\\\\n",
    "&=\\left(\\prod_{i=1}^n \\frac{1}{b}\\right)\\left(\\prod_{i=1}^n I(x_i\\leq b) \\right)\\\\\n",
    "&=\\left(\\frac{1}{b}\\right)^n I(x_1\\leq b \\text{ and } x_2\\leq b \\text{ and...and } x_n\\leq b)\\\\\n",
    "L(b\\mid \\textbf{x})&=(b^{-n}) I(\\text{max}(\\textbf{x})\\leq b)\\\\\n",
    "\\frac{d}{db}L(b\\mid \\textbf{x})&=\\frac{d}{db} (b^{-n}) \\text{ where }b\\geq\\text{max}(\\textbf{x})\\\\\n",
    "0&=-n b^{-n-1} \\text{ where }b\\geq\\text{max}(\\textbf{x})\\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Since $\\frac{-n}{b^{n+1}}\\neq 0$ for all b, there is no relative maximum to the likelihood function. Therefore, the maximum likelihood must be at an endpoint of the function:*\n",
    "\n",
    "$\\lim_{b\\rightarrow\\infty} L(b\\mid \\textbf{x})=0\\\\\n",
    "L(\\text{max}(\\textbf{x})\\mid\\textbf{x})=\\frac{1}{\\text{max}(\\textbf{x})^n}>0$\n",
    "\n",
    "*Therefore we know that the most likely value for b is $b=\\text{max}(\\textbf{x})$.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: Binomial Distribution\n",
    "\n",
    "Suppose $X_1,X_2,...,X_n$ is an iid sequence of random variables with the binomial distribution with 20 trials and unknown probability of success $\\pi$. Find the maximum likelihood estimate of $\\pi$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "L(\\pi\\mid \\textbf{x})&=\\prod_{i=1}^n f(x_i;20,\\pi)\\\\\n",
    "&=\\prod_{i=1}^n {20\\choose x_i} \\pi^{x_i} (1-\\pi)^{20-x_i}\\\\\n",
    "&=\\prod_{i=1}^n \\frac{20!}{(20-x_i)! x_i!} \\pi^{x_i} (1-\\pi)^{20-x_i}\\\\\n",
    "L(\\pi\\mid \\textbf{x})&= (20!)^n \\left(\\prod_{i=1}^n\\frac{1}{(20-x_i)! x_i!}\\right) \\pi^{\\left(\\sum_{i=1}^n x_i\\right)} (1-\\pi)^{\\left(\\sum_{i=1}^n (20-x_i)\\right)}\\\\\n",
    "l(\\pi\\mid \\textbf{x})&=n\\log(20!) + \\sum_{i=1}^n \\log\\left(\\frac{1}{(20-x_i)! x_i!}\\right) + \\log\\pi\\sum_{i=1}^n x_i + \\log(1-\\pi)\\sum_{i=1}^n (20-x_i)\\\\\n",
    "l(\\pi\\mid \\textbf{x})&=n\\log(20!) + \\sum_{i=1}^n \\log\\left(\\frac{1}{(20-x_i)! x_i!}\\right) + n\\bar{X}\\log\\pi - 20 n^2 \\bar{X} \\log(1-\\pi)\\\\\n",
    "\\frac{d}{d\\pi}l(\\pi\\mid \\textbf{x})&= 0 + 0 + \\frac{n\\bar{X}}{\\pi} + \\frac{20 n^2 \\bar{X}}{1-\\pi}\\\\\n",
    "0&=\\frac{n\\bar{X}(1-\\hat{\\pi}_{ML})+20 n^2\\bar{X}\\hat{\\pi}_{ML}}{\\hat{\\pi}_{ML}(1-\\hat{\\pi}_{ML})}\\\\\n",
    "0&=1-\\hat{\\pi}_{ML}+20n\\hat{\\pi}_{ML}\\\\\n",
    "\\hat{\\pi}_{ML}&=\\frac{1}{1-20n}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
